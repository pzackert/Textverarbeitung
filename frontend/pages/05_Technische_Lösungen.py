from __future__ import annotations

import logging

import pandas as pd
import streamlit as st

st.set_page_config(page_title="Technische L√∂sungen", layout="wide")

LOGGER = logging.getLogger("frontend.app")
if not LOGGER.handlers:
    handler = logging.StreamHandler()
    handler.setFormatter(logging.Formatter("%(asctime)s %(levelname)s %(message)s"))
    LOGGER.addHandler(handler)
LOGGER.setLevel(logging.INFO)
LOGGER.info("page_view | {'page': 'technische_loesungen'}")

st.header("üí° Technische L√∂sungsoptionen")
st.subheader("Vergleich der drei Implementierungsans√§tze f√ºr das IFB PROFI System")
st.write("Von der schnellen MVP-L√∂sung bis zur skalierbare Cloud-Architektur - hier finden Sie alle technischen Optionen im √úberblick.")

OPTIONS = ["Option 1: LM Studio Lightweight", "Option 2: Custom RAG System", "Option 3: Cloud-basiert Professional"]


def _render_table(df: pd.DataFrame, caption: str | None = None) -> None:
    """Render tables with consistent column widths for readability."""
    column_config = {col: st.column_config.TextColumn(width="medium") for col in df.columns}
    st.dataframe(df, use_container_width=True, column_config=column_config, hide_index=False)
    if caption:
        st.caption(caption)

st.markdown("## Technische L√∂sungsoptionen - Tabellarische √úbersicht")
st.caption("üìä Vergleichsmatrix f√ºr IFB PROFI System")
overview_df = pd.DataFrame(
    {
        "Kriterium": ["Status", "Beschreibung"],
        OPTIONS[0]: ["‚úÖ Aktuell implementiert (MVP)", "LM Studio Backend ¬∑ Streamlit Frontend"],
        OPTIONS[1]: ["üîß Masterprojekt-Ziel", "Custom RAG Plattform mit erweitertem Funktionsumfang"],
        OPTIONS[2]: ["üöÄ Zukunftsoption", "Enterprise Cloud L√∂sung mit unbegrenzter Skalierung"],
    }
)
_render_table(overview_df.set_index("Kriterium"))

st.markdown("### üñ•Ô∏è Hardware-Anforderungen")
hardware_df = pd.DataFrame(
    {
        "Komponente": ["GPU", "GPU-Speicher", "RAM", "CPU", "Speicher", "Hosting"],
        OPTIONS[0]: [
            "NVIDIA RTX 3060 (12GB) / Apple M1/M2",
            "10-16 GB VRAM",
            "16 GB",
            "Mittelklasse (i5/i7, Ryzen 5/7)",
            "100 GB SSD",
            "Lokaler Rechner/Workstation",
        ],
        OPTIONS[1]: [
            "NVIDIA RTX 4090 (24GB) / A6000 (48GB)",
            "24-48 GB VRAM",
            "32-64 GB",
            "High-End (i9, Ryzen 9, Threadripper)",
            "500 GB - 1 TB NVMe",
            "Dedizierter Server/Workstation",
        ],
        OPTIONS[2]: [
            "Cloud GPU (A100 80GB, H100)",
            "40-80 GB VRAM (skalierbar)",
            "64-128 GB (skalierbar)",
            "Cloud vCPUs (16-32 Cores)",
            "Cloud Storage (flexibel)",
            "AWS / Azure / GCP",
        ],
    }
)
_render_table(hardware_df.set_index("Komponente"))

st.markdown("### ‚öôÔ∏è Technische Architektur")
architecture_df = pd.DataFrame(
    {
        "Komponente": ["LLM Backend", "Modelle", "RAG System", "Dokument-Parser", "Vector DB", "Frontend", "API"],
        OPTIONS[0]: [
            "LM Studio (lokal)",
            "Qwen 2.5 (3-7B)",
            "LM Studio integriert",
            "LM Studio Basic",
            "LM Studio intern",
            "Streamlit",
            "LM Studio REST API",
        ],
        OPTIONS[1]: [
            "Custom Python Backend (Ollama/llama.cpp)",
            "Qwen 2.5, Llama 3.1 (8-70B)",
            "Custom ChromaDB + LangChain",
            "PyMuPDF, Unstructured, Custom Parser",
            "ChromaDB (lokal)",
            "FastAPI + HTMX + Tailwind",
            "Custom FastAPI",
        ],
        OPTIONS[2]: [
            "OpenAI / Anthropic / Azure OpenAI",
            "GPT-4, Claude 3.5, Gemini (175B+)",
            "Pinecone / Weaviate (Enterprise)",
            "Adobe PDF Services, AWS Textract",
            "Pinecone, Qdrant, Weaviate (Cloud)",
            "React / Next.js + shadcn/ui",
            "RESTful + GraphQL",
        ],
    }
)
_render_table(architecture_df.set_index("Komponente"))

st.markdown("### üéØ Funktionen & Capabilities")
functions_df = pd.DataFrame(
    {
        "Funktion": [
            "Dokument-Formate",
            "RAG-Qualit√§t",
            "Chunking",
            "Embedding-Modelle",
            "Batch-Verarbeitung",
            "Multi-User",
            "Monitoring",
            "Fehlerbehandlung",
        ],
        OPTIONS[0]: [
            "PDF, DOCX, TXT (Basic)",
            "Standard",
            "Basic (feste Gr√∂√üe)",
            "all-MiniLM",
            "Begrenzt",
            "Nein",
            "Terminal-Logs",
            "Basic",
        ],
        OPTIONS[1]: [
            "PDF, DOCX, XLSX, TXT, HTML (Advanced)",
            "Sehr gut",
            "Semantisch intelligent",
            "multilingual-e5, BGE",
            "Ja (Multi-Threading)",
            "Ja (Session-Management)",
            "Prometheus + Grafana",
            "Erweitert mit Retry-Logic",
        ],
        OPTIONS[2]: [
            "Alle Formate + OCR + Scans",
            "Exzellent",
            "KI-gest√ºtzt mit Kontext",
            "OpenAI ada-002, Cohere",
            "Ja (hochskalierbar)",
            "Ja (Enterprise-Authentication)",
            "CloudWatch, DataDog",
            "Enterprise-Grade",
        ],
    }
)
_render_table(functions_df.set_index("Funktion"))

st.markdown("### üí∞ Kosten & Aufwand")
cost_df = pd.DataFrame(
    {
        "Kostenart": [
            "Hardware (einmalig)",
            "Software-Lizenzen",
            "Monatliche Kosten",
            "API-Kosten pro 1M Token",
            "Entwicklungszeit",
            "Wartungsaufwand",
        ],
        OPTIONS[0]: [
            "1.500 - 2.500 ‚Ç¨",
            "0 ‚Ç¨ (Open Source)",
            "~30 ‚Ç¨ (Strom)",
            "0 ‚Ç¨",
            "2-4 Wochen (fertig)",
            "Niedrig",
        ],
        OPTIONS[1]: [
            "3.000 - 8.000 ‚Ç¨",
            "0 ‚Ç¨ (Open Source)",
            "~50-100 ‚Ç¨ (Strom/Wartung)",
            "0 ‚Ç¨",
            "3-4 Monate",
            "Mittel",
        ],
        OPTIONS[2]: [
            "0 ‚Ç¨ (Cloud)",
            "Variable (API-Kosten)",
            "500 - 2.000 ‚Ç¨",
            "5-30 ‚Ç¨",
            "6-12 Monate",
            "Niedrig (Managed)",
        ],
    }
)
_render_table(cost_df.set_index("Kostenart"))

st.markdown("### ‚úÖ Vorteile")
advantages_df = pd.DataFrame(
    {
        "Aspekt": [
            "Datenschutz",
            "Einstiegsh√ºrde",
            "Time-to-Market",
            "Kosten",
            "Flexibilit√§t",
            "Performance",
            "Anpassbarkeit",
        ],
        OPTIONS[0]: [
            "‚úÖ 100% lokal",
            "‚úÖ Sehr niedrig",
            "‚úÖ Sofort einsatzbereit",
            "‚úÖ Sehr g√ºnstig",
            "‚ö†Ô∏è Begrenzt durch LM Studio",
            "‚ö†Ô∏è Gut f√ºr 3-7B Modelle",
            "‚ùå Begrenzt",
        ],
        OPTIONS[1]: [
            "‚úÖ 100% lokal",
            "‚ö†Ô∏è Mittel",
            "‚ö†Ô∏è 3-4 Monate",
            "‚úÖ Mittlere Investition",
            "‚úÖ Vollst√§ndig anpassbar",
            "‚úÖ Sehr gut f√ºr 8-70B",
            "‚úÖ Custom",
        ],
        OPTIONS[2]: [
            "‚ö†Ô∏è Cloud-abh√§ngig",
            "‚ö†Ô∏è Cloud-Setup",
            "‚ö†Ô∏è 6+ Monate",
            "‚ùå Hohe laufende Kosten",
            "‚úÖ Hoch skalierbar",
            "‚úÖ Exzellent",
            "‚úÖ API-basiert erweiterbar",
        ],
    }
)
_render_table(advantages_df.set_index("Aspekt"))

st.markdown("### ‚ùå Nachteile")
disadvantages_df = pd.DataFrame(
    {
        "Aspekt": [
            "Skalierbarkeit",
            "Modell-Gr√∂√üe",
            "Dokument-Parsing",
            "Multi-User",
            "UI/UX",
            "Wartung",
            "Vendor Lock-in",
        ],
        OPTIONS[0]: [
            "‚ùå Begrenzt auf einen Rechner",
            "‚ùå Max. 7B realistisch",
            "‚ùå Basic",
            "‚ùå Single-User",
            "‚ùå Streamlit-Limitierungen",
            "‚úÖ Minimal",
            "‚úÖ Kein Lock-in",
        ],
        OPTIONS[1]: [
            "‚ö†Ô∏è Horizontal skalierbar (Aufwand)",
            "‚ö†Ô∏è Max. 70B",
            "‚úÖ Erweitert",
            "‚úÖ M√∂glich",
            "‚úÖ Modern",
            "‚ö†Ô∏è Mittel",
            "‚úÖ Kein Lock-in",
        ],
        OPTIONS[2]: [
            "‚úÖ Automatisch skalierbar",
            "‚úÖ Unbegrenzt",
            "‚úÖ Enterprise-Level",
            "‚úÖ Native Unterst√ºtzung",
            "‚úÖ State-of-the-art",
            "‚úÖ Managed",
            "‚ö†Ô∏è Cloud-Abh√§ngigkeit",
        ],
    }
)
_render_table(disadvantages_df.set_index("Aspekt"))

st.markdown("### üìà Performance & Qualit√§t")
performance_df = pd.DataFrame(
    {
        "Metrik": ["Antwortzeit", "Tokens/Sekunde", "RAG-Accuracy", "Dokument-Verarbeitung", "Gleichzeitige Nutzer"],
        OPTIONS[0]: ["5-15 s (3B)", "20-40", "70-80%", "1-2 Dokumente parallel", "1-5"],
        OPTIONS[1]: ["10-30 s (13B)", "40-80", "80-90%", "5-10 Dokumente parallel", "5-10"],
        OPTIONS[2]: ["2-5 s", "100-200", "90-95%", "Unbegrenzt", "100+"],
    }
)
_render_table(performance_df.set_index("Metrik"))

st.markdown("### üîß Entwicklungsaufwand")
effort_df = pd.DataFrame(
    {
        "Phase": ["Setup", "Entwicklung", "Testing", "Deployment", "Dokumentation"],
        OPTIONS[0]: ["1 Tag", "2-4 Wochen (fertig)", "1 Woche", "Lokal (sofort)", "Basic"],
        OPTIONS[1]: ["1-2 Wochen", "3-4 Monate", "2-4 Wochen", "On-Premise (1 Woche)", "Umfassend"],
        OPTIONS[2]: ["1-2 Wochen", "6-12 Monate", "4-8 Wochen", "Cloud (2-4 Wochen)", "Enterprise-Level"],
    }
)
_render_table(effort_df.set_index("Phase"))

st.divider()
with st.container():
    st.header("üß≠ Bewertung & Empfehlung")
    st.write(
        "Option 1 bleibt das produktionsreife MVP, Option 2 ist das konkrete Masterprojekt-Ziel und Option 3 bildet die skalierbare Roadmap nach erfolgreichem Projektabschluss."
    )
    rating_cols = st.columns(3)
    with rating_cols[0]:
        st.metric("Option 1", "Score: 7/10", "Sofort nutzbar")
        st.success("Ideal f√ºr Demo & lokale Eins√§tze")
    with rating_cols[1]:
        st.metric("Option 2", "Score: 8/10", "Masterprojekt")
        st.info("Beste Balance aus Kontrolle, Funktionsumfang und Datenschutz")
    with rating_cols[2]:
        st.metric("Option 3", "Score: 6/10", "Roadmap")
        st.warning("Hoher Aufwand, lohnt f√ºr Enterprise-Szenarien")

st.divider()
with st.container():
    st.header("üéì Fahrplan")
    st.info(
        """
        Phase 1 (Aktuell): Option 1 - MVP Demo (standalone, lokal und einsatzbereit)

        Phase 2 (Masterprojekt): Option 2 - Custom Development (RAG-Platform mit erweiterten Modellen)

        Phase 3 (Nach Projekt): Option 3 - Cloud Migration (Enterprise-Scale, Managed Services)
        """
    )