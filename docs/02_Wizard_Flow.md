# Wizard-Flow
## IFB PROFI - Automatisierte AntragsprÃ¼fung

**Version:** 3.0  
**Stand:** 10. November 2025

---

## ğŸ¯ ÃœBERSICHT

Der Wizard fÃ¼hrt Benutzer **Step-by-Step** durch die automatisierte AntragsprÃ¼fung. Jeder Schritt baut auf dem vorherigen auf und ist klar abgegrenzt.

### Prozess-Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                      â”‚
â”‚  Schritt 0: ProjektÃ¼bersicht                        â”‚
â”‚  â†’ Bestehendes Projekt Ã¶ffnen ODER neu anlegen      â”‚
â”‚                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                      â”‚
â”‚  Schritt 1: Projekt anlegen                         â”‚
â”‚  â†’ Metadaten erfassen (Name, Firma, Modul)          â”‚
â”‚                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                      â”‚
â”‚  Schritt 2: Dokumente hochladen                     â”‚
â”‚  â†’ Projektskizze + Projektantrag hochladen          â”‚
â”‚                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                      â”‚
â”‚  Schritt 3: Automatische Verarbeitung               â”‚
â”‚  â†’ Parsing â†’ RAG-Aufbau â†’ KriterienprÃ¼fung          â”‚
â”‚                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                      â”‚
â”‚  Schritt 4: ErgebnisÃ¼bersicht                       â”‚
â”‚  â†’ PrÃ¼fungsergebnisse anzeigen & exportieren        â”‚
â”‚                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```


---

## ğŸ“‹ SCHRITT 0: PROJEKTÃœBERSICHT

**Zweck:** Einstiegspunkt der Anwendung - Ãœberblick Ã¼ber alle Projekte

### Was passiert hier?
- Anzeige aller angelegten Projekte in tabellarischer Form
- Status-Ãœbersicht (Neu, In Bearbeitung, Abgeschlossen)
- Navigation zu bestehenden Projekten
- Button zum Anlegen eines neuen Projekts

### Output
- User wÃ¤hlt bestehendes Projekt ODER legt neues an

**UI-Details:** Siehe `01_UI_FLOW.md` â†’ Seite 0

---

## ğŸ“‹ SCHRITT 1: PROJEKT ANLEGEN

**Zweck:** Grunddaten des FÃ¶rderprojekts erfassen

### Was passiert hier?
- User gibt Projekt-Metadaten ein:
  - Projektname
  - Antragsteller/Firma
  - FÃ¶rdermodul (PROFI Standard, Transfer, etc.)
  - Projektart (Forschung, Entwicklung, Studie)
  
### Backend-Aktion
System erstellt automatisch:
- Projekt-ID (eindeutig)
- Ordnerstruktur im Dateisystem
- `metadata.json` mit Projekt-Informationen

### Output
- Projekt ist angelegt und bereit fÃ¼r Dokumenten-Upload
- User wird zu Schritt 2 weitergeleitet

**Datenstruktur:** Siehe `06_DATA_MANAGEMENT.md`  
**UI-Details:** Siehe `01_UI_FLOW.md` â†’ Seite 1

---

## ğŸ“‹ SCHRITT 2: DOKUMENTE HOCHLADEN

**Zweck:** Alle erforderlichen Dokumente in das System laden

### Was passiert hier?
User lÃ¤dt 2 Haupt-Dokumente hoch:

1. **Projektskizze** (2-3 Seiten)
   - Format: PDF oder DOCX
   - EnthÃ¤lt: Projektbeschreibung, Marktanalyse, etc.

2. **Projektantrag** (Formular + AnhÃ¤nge)
   - Format: PDF oder DOCX
   - EnthÃ¤lt: Strukturierte Antragsdaten

Optional: Weitere Dokumente (LebenslÃ¤ufe, Letters of Intent, etc.)

### Backend-Aktion
- Dateien werden im Projekt-Ordner gespeichert
- Metadaten werden aktualisiert (Dateiname, GrÃ¶ÃŸe, Upload-Zeit)
- Dateityp-Validierung

### Output
- Alle Dokumente sind hochgeladen
- System ist bereit fÃ¼r automatische Verarbeitung
- User wird zu Schritt 3 weitergeleitet

**Parsing-Details:** Siehe `02_DOCUMENT_PARSING.md`  
**UI-Details:** Siehe `01_UI_FLOW.md` â†’ Seite 2

---

## ğŸ“‹ SCHRITT 3: AUTOMATISCHE VERARBEITUNG

**Zweck:** Dokumente analysieren und Kriterien prÃ¼fen

### Was passiert hier?

#### Phase 3.1: Parsing
- System extrahiert Text aus allen hochgeladenen Dokumenten
- Strukturdaten werden erkannt (Ãœberschriften, Tabellen, etc.)
- Status-Anzeige: "Parsing lÃ¤uft..."

#### Phase 3.2: RAG-Aufbau
- Texte werden in Chunks aufgeteilt
- Embeddings werden generiert
- ChromaDB wird mit Vektoren befÃ¼llt
- Status-Anzeige: "RAG-Index wird erstellt..."

#### Phase 3.3: KriterienprÃ¼fung
LLM prÃ¼ft sukzessive alle 6 FÃ¶rderkriterien:

1. **K001: Projektort** - BetriebsstÃ¤tte in Hamburg?
2. **K002: Unternehmensalter** - Min. 2 Jahre?
3. **K003: Projektbeginn** - Noch nicht begonnen?
4. **K004: Projektziel** - Neue/verbesserte Produkte?
5. **K005: Finanzierung** - 10k-100k EUR, gesichert?
6. **K006: Erfolgsaussicht** - Ohne FÃ¶rderung nicht realisierbar?

FÃ¼r jedes Kriterium:
- RAG findet relevante Textstellen
- LLM bewertet: ErfÃ¼llt / Nicht erfÃ¼llt / Unklar
- BegrÃ¼ndung wird generiert
- Status wird live aktualisiert

### UI-Verhalten wÃ¤hrend Verarbeitung

**Oberer Bereich:** Prozess-Status
```
â³ Parsing...        âœ“ Abgeschlossen
â³ RAG-Aufbau...     â³ 45% (23/50 Chunks)
â¹  LLM-PrÃ¼fung      â¹ Wartet...
```

**Unterer Bereich:** Kriterienliste (Live-Updates)
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Kriterium              â”‚ Status  â”‚ Konfidenz  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ K001: Projektort       â”‚ âœ“       â”‚ 95%        â”‚
â”‚ K002: Unternehmensalterâ”‚ âœ“       â”‚ 88%        â”‚
â”‚ K003: Projektbeginn    â”‚ â³      â”‚ -          â”‚
â”‚ K004: Projektziel      â”‚ â¹      â”‚ -          â”‚
â”‚ K005: Finanzierung     â”‚ â¹      â”‚ -          â”‚
â”‚ K006: Erfolgsaussicht  â”‚ â¹      â”‚ -          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Backend-Aktionen
- Parser-Module verarbeiten Dokumente
- RAG-System indexiert Inhalte
- Criteria-Engine fÃ¼hrt LLM-Checks durch
- Ergebnisse werden in `metadata.json` gespeichert

### Output
- Alle Kriterien sind geprÃ¼ft (âœ“, âœ—, oder âš ï¸)
- Detaillierte BegrÃ¼ndungen fÃ¼r jedes Kriterium
- System wechselt automatisch zu Schritt 4

**Parsing-Details:** Siehe `02_DOCUMENT_PARSING.md`  
**RAG-Details:** Siehe `03_RAG_SYSTEM.md`  
**Kriterien-Details:** Siehe `05_CRITERIA_ENGINE.md`  
**UI-Details:** Siehe `01_UI_FLOW.md` â†’ Seite 3

---

## ğŸ“‹ SCHRITT 4: ERGEBNISÃœBERSICHT

**Zweck:** PrÃ¼fungsergebnisse prÃ¤sentieren und exportieren

### Was passiert hier?

#### Zusammenfassung
```
PrÃ¼fung abgeschlossen: 5 von 6 Kriterien erfÃ¼llt

âœ“ K001: Projektort Hamburg
âœ“ K002: Unternehmensalter
âœ— K003: Projektbeginn (bereits begonnen)
âœ“ K004: Projektziel  
âœ“ K005: Finanzierung
âœ“ K006: Erfolgsaussicht
```

#### Detailansicht
FÃ¼r jedes Kriterium:
- Status (ErfÃ¼llt / Nicht erfÃ¼llt)
- BegrÃ¼ndung (aus LLM-Analyse)
- Quellen (relevante Dokumenten-Abschnitte)
- Konfidenz-Score
- Option zur manuellen Korrektur

#### Export-Funktionen
User kann Ergebnisse exportieren als:
- **PDF** - DruckfÃ¤higer PrÃ¼fbericht
- **JSON** - Maschinenlesbare Daten
- **Markdown** - Text-Format fÃ¼r Weiterverarbeitung

### Backend-Aktion
- Report-Generator erstellt strukturierte Ausgabe
- Export-Files werden im Results-Ordner gespeichert

### Output
- VollstÃ¤ndige Dokumentation der PrÃ¼fung
- Downloadbare Reports
- Projekt-Status wird auf "Abgeschlossen" gesetzt

**UI-Details:** Siehe `01_UI_FLOW.md` â†’ Seite 4

---

## ğŸ”„ WIZARD-NAVIGATION

### VorwÃ¤rts-Navigation
Jeder Schritt hat einen "Weiter"-Button, der erst aktiviert wird, wenn:
- Alle erforderlichen Daten eingegeben sind (Schritt 1)
- Alle Pflichtdokumente hochgeladen sind (Schritt 2)
- Die Verarbeitung abgeschlossen ist (Schritt 3)

### RÃ¼ckwÃ¤rts-Navigation
User kann jederzeit zu vorherigen Schritten zurÃ¼ck:
- Projektdaten anpassen
- Dokumente austauschen
- PrÃ¼fung neu durchfÃ¼hren

### Projekt speichern
Nach jedem Schritt wird der Projekt-Zustand automatisch gespeichert:
- User kann Anwendung schlieÃŸen und spÃ¤ter fortsetzen
- Letzter Status wird in `metadata.json` festgehalten

---

## ğŸ¯ GESAMTABLAUF (ZUSAMMENFASSUNG)

```
Schritt 0: ProjektÃ¼bersicht
  â†’ Projekt auswÃ¤hlen oder neu anlegen
  
Schritt 1: Projekt anlegen
  â†’ Metadaten erfassen
  â†’ Ordnerstruktur wird erstellt
  
Schritt 2: Dokumente hochladen
  â†’ Projektskizze + Projektantrag
  â†’ Dateien werden gespeichert
  
Schritt 3: Automatische Verarbeitung
  â†’ Parsing (Text extrahieren)
  â†’ RAG-Aufbau (Vektoren indexieren)
  â†’ KriterienprÃ¼fung (6 Checks nacheinander)
  â†’ Live-Status-Updates in UI
  
Schritt 4: ErgebnisÃ¼bersicht
  â†’ Zusammenfassung (x/6 erfÃ¼llt)
  â†’ Detaillierte BegrÃ¼ndungen
  â†’ Export (PDF, JSON, Markdown)
```

**GeschÃ¤tzte Dauer:** 5-10 Minuten pro Projekt

---

## ğŸ“š VERWANDTE DOKUMENTE

- **UI-Implementierung:** `01_UI_FLOW.md`
- **Dokumenten-Parsing:** `02_DOCUMENT_PARSING.md`
- **RAG-System:** `03_RAG_SYSTEM.md`
- **LLM-Integration:** `04_LLM_INTEGRATION.md`
- **Kriterien-Engine:** `05_CRITERIA_ENGINE.md`
- **Datenmanagement:** `06_DATA_MANAGEMENT.md`

---

**Ende der Wizard-Flow Dokumentation**
                
                st.success(f"âœ… Erfolgreich geparst")
                st.json(parse_result["metadata"])
                
                # Metadaten aktualisieren
                doc["parsed"] = True
                doc["parsed_at"] = datetime.now().isoformat()
                
            except Exception as e:
                st.error(f"âŒ Fehler: {str(e)}")
        
        parsed_count += 1
        progress_bar.progress(parsed_count / total_docs)

# Speichern
save_projekt_metadata(projekt_id, metadata)
metadata["checks_completed"]["parsing"] = True

status_text.text("âœ… Alle Dokumente geparst!")

# Weiter-Button
if st.button("â¡ï¸ Weiter zu Schritt 4: Informationsextraktion"):
    st.switch_page("pages/4_Extraktion.py")
```

### Backend-Logik

```python
# backend/parsers/parser_factory.py

from pathlib import Path
from .pdf_parser import PDFParser
from .docx_parser import DOCXParser
from .xlsx_parser import XLSXParser

def parse_document(projekt_id: str, doc_type: str) -> dict:
    """WÃ¤hlt richtigen Parser und parst Dokument."""
    
    # 1. Dokument finden
    metadata = load_projekt_metadata(projekt_id)
    doc = next(d for d in metadata["documents"] if d["doc_type"] == doc_type)
    
    file_path = Path(f"data/projects/{projekt_id}/uploads/{doc['filename']}")
    
    # 2. Parser wÃ¤hlen
    suffix = file_path.suffix.lower()
    
    if suffix == ".pdf":
        parser = PDFParser()
    elif suffix == ".docx":
        parser = DOCXParser()
    elif suffix in [".xlsx", ".xls"]:
        parser = XLSXParser()
    else:
        raise ValueError(f"Unsupported file format: {suffix}")
    
    # 3. Parsen
    result = parser.parse(file_path)
    
    # 4. Extrahierte Daten speichern
    extracted_path = Path(f"data/projects/{projekt_id}/extracted/{doc_type}.json")
    with open(extracted_path, "w", encoding="utf-8") as f:
        json.dump(result, f, indent=2, ensure_ascii=False)
    
    return result
```

### Output
- Geparste Daten in `data/projects/projekt_XXX/extracted/`
- Eine JSON-Datei pro Dokument

---

## SCHRITT 4: INFORMATIONSEXTRAKTION (RAG)

### Ziel
Strukturierte Informationen aus den Dokumenten extrahieren und in ChromaDB indexieren.

### UI-Elemente (Streamlit)

```python
# frontend/pages/4_Extraktion.py

import streamlit as st

st.title("ğŸ“Š Informationsextraktion")

projekt_id = st.session_state.get("current_projekt_id")
metadata = load_projekt_metadata(projekt_id)

st.info("ğŸ¤– LLM extrahiert strukturierte Daten aus den Dokumenten...")

# RAG-Pipeline starten
with st.spinner("Dokumente werden in Vector-DB indexiert..."):
    # 1. Alle extrahierten Texte laden
    extracted_texts = load_all_extracted_texts(projekt_id)
    
    # 2. Chunking
    chunks = chunk_texts(extracted_texts)
    st.write(f"âœ… {len(chunks)} Text-Chunks erstellt")
    
    # 3. Embeddings erstellen
    embeddings = create_embeddings(chunks)
    st.write(f"âœ… Embeddings erstellt")
    
    # 4. In ChromaDB speichern
    vector_ids = store_in_chromadb(projekt_id, chunks, embeddings)
    st.write(f"âœ… {len(vector_ids)} Chunks in Vector-DB gespeichert")

# Strukturierte Extraktion
st.subheader("ğŸ” Strukturierte Datenextraktion")

with st.spinner("LLM extrahiert strukturierte Felder..."):
    extracted_data = extract_structured_data(projekt_id)

# Anzeige extrahierter Daten
col1, col2 = st.columns(2)

with col1:
    st.metric("Projektlaufzeit", f"{extracted_data['projekt_details']['laufzeit_monate']} Monate")
    st.metric("Gesamtkosten", f"{extracted_data['projekt_details']['gesamtkosten']:,.2f} â‚¬")

with col2:
    st.metric("Beantragte FÃ¶rderung", f"{extracted_data['projekt_details']['beantragte_foerderung']:,.2f} â‚¬")
    st.metric("FÃ¶rderquote", f"{extracted_data['projekt_details']['foerderquote']*100:.1f}%")

# Unternehmensdaten
st.subheader("ğŸ¢ Unternehmensdaten")
st.write(f"**Name:** {extracted_data['unternehmen']['name']}")
st.write(f"**Mitarbeiter:** {extracted_data['unternehmen']['mitarbeiter']}")
st.write(f"**Standort:** {extracted_data['unternehmen']['standort']['ort']}")
st.write(f"**KMU-Status:** {'âœ… Ja' if extracted_data['unternehmen']['kmu_status']['ist_kmu'] else 'âŒ Nein'}")

# Personalkosten-Tabelle
st.subheader("ğŸ‘¥ Personalkosten")
import pandas as pd

personal_df = pd.DataFrame(extracted_data['personalkosten']['mitarbeiter'])
st.dataframe(personal_df[['rolle', 'abschluss', 'personenmonate', 'kosten_gesamt']])

# Speichern
metadata["extracted_data"] = extracted_data
metadata["checks_completed"]["extraction"] = True
save_projekt_metadata(projekt_id, metadata)

st.success("âœ… Informationsextraktion abgeschlossen!")

# Weiter-Button
if st.button("â¡ï¸ Weiter zu Schritt 5: FÃ¶rdervoraussetzungen prÃ¼fen"):
    st.switch_page("pages/5_Foerdervoraussetzungen.py")
```

### Backend-Logik

```python
# backend/rag/extractor.py

from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.vectorstores import Chroma

def chunk_texts(texts: dict) -> list:
    """Chunked Texte fÃ¼r RAG."""
    
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=1000,
        chunk_overlap=200,
        separators=["\n\n", "\n", ". ", " ", ""]
    )
    
    chunks = []
    for doc_type, text in texts.items():
        doc_chunks = text_splitter.split_text(text)
        
        for i, chunk in enumerate(doc_chunks):
            chunks.append({
                "text": chunk,
                "metadata": {
                    "doc_type": doc_type,
                    "chunk_index": i
                }
            })
    
    return chunks

def store_in_chromadb(projekt_id: str, chunks: list, embeddings) -> list:
    """Speichert Chunks in ChromaDB."""
    
    vectorstore = Chroma(
        collection_name=f"projekt_{projekt_id}",
        embedding_function=embeddings,
        persist_directory="data/chromadb"
    )
    
    texts = [c["text"] for c in chunks]
    metadatas = [c["metadata"] for c in chunks]
    
    vector_ids = vectorstore.add_texts(texts, metadatas=metadatas)
    
    return vector_ids

def extract_structured_data(projekt_id: str) -> dict:
    """Extrahiert strukturierte Daten mit LLM."""
    
    # RAG-Retriever initialisieren
    retriever = get_retriever(projekt_id)
    llm = get_lm_studio_client()
    
    # Verschiedene Extraktion-Tasks
    projekt_details = extract_projekt_details(retriever, llm)
    unternehmen = extract_unternehmen_data(retriever, llm)
    personalkosten = extract_personalkosten(retriever, llm)
    
    return {
        "projekt_details": projekt_details,
        "unternehmen": unternehmen,
        "personalkosten": personalkosten
    }
```

### Output
- Chunks in ChromaDB indexiert
- Strukturierte Daten in `metadata.json` unter `extracted_data`

---

## SCHRITT 5: FÃ–RDERVORAUSSETZUNGEN PRÃœFEN

### Ziel
Alle 6 FÃ¶rdervoraussetzungen prÃ¼fen und Checkliste erstellen.

### UI-Elemente (Streamlit)

```python
# frontend/pages/5_Foerdervoraussetzungen.py

import streamlit as st

st.title("âœ… FÃ¶rdervoraussetzungen prÃ¼fen")

projekt_id = st.session_state.get("current_projekt_id")
metadata = load_projekt_metadata(projekt_id)

st.subheader("ğŸ” Automatische PrÃ¼fung lÃ¤uft...")

# PrÃ¼fung durchfÃ¼hren
with st.spinner("LLM prÃ¼ft FÃ¶rdervoraussetzungen..."):
    check_results = check_foerdervoraussetzungen(projekt_id)

# Ergebnisse anzeigen
for i, (key, result) in enumerate(check_results.items(), 1):
    with st.expander(f"{i}. {result['kriterium']}", expanded=True):
        
        # Status
        if result['erfuellt']:
            st.success(f"âœ… ErfÃ¼llt")
        else:
            st.error(f"âŒ Nicht erfÃ¼llt")
        
        # Details
        col1, col2 = st.columns([1, 2])
        
        with col1:
            st.write("**Wert:**")
            st.code(result['wert'])
        
        with col2:
            st.write("**BegrÃ¼ndung:**")
            st.write(result['begruendung'])
        
        # Quellen
        st.write("**Quellen:**")
        for source in result['quellen']:
            st.write(f"- {source}")
        
        # Confidence
        st.progress(result['confidence'])
        st.caption(f"Confidence: {result['confidence']*100:.0f}%")

# Gesamtergebnis
alle_erfuellt = all(r['erfuellt'] for r in check_results.values())

st.divider()

if alle_erfuellt:
    st.success("âœ… **Alle FÃ¶rdervoraussetzungen erfÃ¼llt!**")
else:
    st.error("âŒ **Nicht alle FÃ¶rdervoraussetzungen erfÃ¼llt.**")
    nicht_erfuellt = [r['kriterium'] for r in check_results.values() if not r['erfuellt']]
    st.warning(f"Nicht erfÃ¼llt: {', '.join(nicht_erfuellt)}")

# Checkliste herunterladen
checkliste_md = generate_checkliste_markdown(check_results)
st.download_button(
    label="ğŸ“¥ Checkliste als Markdown herunterladen",
    data=checkliste_md,
    file_name=f"foerdervoraussetzungen_{projekt_id}.md",
    mime="text/markdown"
)

# Speichern
metadata["pruefung"] = {
    "foerdervoraussetzungen": check_results,
    "alle_erfuellt": alle_erfuellt,
    "geprueft_am": datetime.now().isoformat()
}
metadata["checks_completed"]["foerdervoraussetzungen"] = True
save_projekt_metadata(projekt_id, metadata)

# Weiter-Button
if st.button("â¡ï¸ Weiter zu Schritt 6: Bewertung"):
    st.switch_page("pages/6_Bewertung.py")
```

### Backend-Logik

```python
# backend/rules/foerdervoraussetzungen.py

def check_foerdervoraussetzungen(projekt_id: str) -> dict:
    """FÃ¼hrt alle 6 Checks durch."""
    
    retriever = get_retriever(projekt_id)
    llm = get_lm_studio_client()
    
    return {
        "projektort": check_projektort(retriever, llm, projekt_id),
        "unternehmensalter": check_unternehmensalter(retriever, llm, projekt_id),
        "projektbeginn": check_projektbeginn(retriever, llm, projekt_id),
        "projektziel": check_projektziel(retriever, llm, projekt_id),
        "finanzierung": check_finanzierung(retriever, llm, projekt_id),
        "erfolgsaussicht": check_erfolgsaussicht(retriever, llm, projekt_id)
    }

def check_projektort(retriever, llm, projekt_id: str) -> dict:
    """PrÃ¼ft: BetriebsstÃ¤tte in Hamburg?"""
    
    # 1. RAG: Relevante Dokumente
    docs = retriever.invoke(
        "BetriebsstÃ¤tte Hamburg Standort Adresse Handelsregister"
    )
    
    # 2. LLM-Check
    prompt = f"""PrÃ¼fe anhand der folgenden Dokumente: Hat das Unternehmen eine BetriebsstÃ¤tte in Hamburg?

Dokumente:
{'\n\n'.join([d.page_content for d in docs[:3]])}

Antworte im JSON-Format:
{{
    "hat_betriebsstÃ¤tte": true/false,
    "adresse": "VollstÃ¤ndige Adresse",
    "begruendung": "Kurze BegrÃ¼ndung",
    "confidence": 0.95
}}"""
    
    response = llm.invoke(prompt)
    result = json.loads(response)
    
    return {
        "kriterium": "Projektort in Hamburg",
        "erfuellt": result["hat_betriebsstÃ¤tte"],
        "wert": result["adresse"],
        "begruendung": result["begruendung"],
        "quellen": [d.metadata.get("source", "unknown") for d in docs],
        "confidence": result["confidence"]
    }

# ... analog fÃ¼r die anderen 5 Checks
```

### Output
- PrÃ¼fergebnisse in `metadata.json` unter `pruefung.foerdervoraussetzungen`
- Checkliste als Markdown-Download

---

## SCHRITT 6: BEWERTUNG DURCHFÃœHREN

### Ziel
Projekt nach 5 Bewertungskriterien bewerten und Scoring durchfÃ¼hren.

### UI-Elemente (Streamlit)

```python
# frontend/pages/6_Bewertung.py

import streamlit as st
import plotly.graph_objects as go

st.title("ğŸŒŸ Bewertung nach Kriterien")

projekt_id = st.session_state.get("current_projekt_id")
metadata = load_projekt_metadata(projekt_id)

st.subheader("ğŸ¤– LLM bewertet das Projekt...")

# Bewertung durchfÃ¼hren
with st.spinner("Bewertung lÃ¤uft..."):
    bewertung = bewerten_projekt(projekt_id)

# Radar-Chart
st.subheader("ğŸ“Š Bewertungsprofil")

categories = [
    "Produktidee",
    "Innovationsgrad",
    "Team",
    "Vermarktung",
    "Arbeitsplatz/Umwelt"
]

values = [
    bewertung["produktidee"]["score"],
    bewertung["innovationsgrad"]["score"],
    bewertung["team"]["score"],
    bewertung["vermarktung"]["score"],
    bewertung["arbeitsplatz_umwelt"]["score"]
]

fig = go.Figure()
fig.add_trace(go.Scatterpolar(
    r=values,
    theta=categories,
    fill='toself',
    name='Bewertung'
))

fig.update_layout(
    polar=dict(radialaxis=dict(visible=True, range=[0, 100])),
    showlegend=False,
    height=500
)

st.plotly_chart(fig, use_container_width=True)

# Einzelne Kriterien
st.subheader("ğŸ“‹ Detaillierte Bewertung")

for i, (key, result) in enumerate(bewertung.items(), 1):
    with st.expander(f"{i}. {key.replace('_', ' ').title()}", expanded=False):
        
        # Score
        st.metric(
            "Score",
            f"{result['score']}/100",
            delta=f"{result['score'] - 75} vs. Durchschnitt"
        )
        
        # BegrÃ¼ndung
        st.write("**BegrÃ¼ndung:**")
        st.write(result['begruendung'])
        
        # StÃ¤rken
        st.write("**StÃ¤rken:**")
        for staerke in result['staerken']:
            st.write(f"âœ… {staerke}")
        
        # SchwÃ¤chen
        st.write("**SchwÃ¤chen:**")
        for schwaeche in result['schwaechen']:
            st.write(f"âš ï¸ {schwaeche}")

# Gesamtbewertung
st.divider()

gesamtscore = sum(
    result['score'] * result.get('gewichtung', 0.2)
    for result in bewertung.values()
)

col1, col2, col3 = st.columns(3)

with col1:
    st.metric("Gesamtscore", f"{gesamtscore:.1f}/100")

with col2:
    if gesamtscore >= 80:
        note = "Sehr gut"
        color = "green"
    elif gesamtscore >= 65:
        note = "Gut"
        color = "green"
    elif gesamtscore >= 50:
        note = "Befriedigend"
        color = "orange"
    else:
        note = "Unzureichend"
        color = "red"
    
    st.metric("Gesamtnote", note)

with col3:
    if gesamtscore >= 65:
        empfehlung = "âœ… Aufforderung"
    elif gesamtscore >= 50:
        empfehlung = "âš ï¸ Ãœberarbeitung"
    else:
        empfehlung = "âŒ Ablehnung"
    
    st.metric("Empfehlung", empfehlung)

# Speichern
metadata["bewertung"] = bewertung
metadata["gesamtscore"] = gesamtscore
metadata["empfehlung"] = empfehlung
metadata["checks_completed"]["bewertung"] = True
save_projekt_metadata(projekt_id, metadata)

# Weiter-Button
if st.button("â¡ï¸ Weiter zu Schritt 7: Report generieren"):
    st.switch_page("pages/7_Report.py")
```

### Backend-Logik

```python
# backend/rules/bewertung.py

def bewerten_projekt(projekt_id: str) -> dict:
    """Bewertet Projekt nach 5 Kriterien."""
    
    retriever = get_retriever(projekt_id)
    llm = get_lm_studio_client()
    
    return {
        "produktidee": bewerte_produktidee(retriever, llm),
        "innovationsgrad": bewerte_innovationsgrad(retriever, llm),
        "team": bewerte_team(retriever, llm),
        "vermarktung": bewerte_vermarktung(retriever, llm),
        "arbeitsplatz_umwelt": bewerte_arbeitsplatz_umwelt(retriever, llm)
    }

def bewerte_produktidee(retriever, llm) -> dict:
    """Bewertet Produktidee (0-100 Punkte)."""
    
    # RAG
    docs = retriever.invoke(
        "Produktidee Innovation Alleinstellungsmerkmal Wettbewerbsvorteil Kundennutzen"
    )
    
    # LLM-Bewertung
    prompt = f"""Bewerte die PRODUKTIDEE nach folgenden Kriterien (0-100 Punkte):
1. Verbesserungen gegenÃ¼ber bestehenden LÃ¶sungen
2. Alleinstellungsmerkmale / Wettbewerbsvorteile
3. Kundennutzen

Dokumente:
{'\n\n'.join([d.page_content for d in docs[:5]])}

Antworte im JSON-Format:
{{
    "score": 87,
    "gewichtung": 0.20,
    "begruendung": "Detaillierte BegrÃ¼ndung...",
    "staerken": ["StÃ¤rke 1", "StÃ¤rke 2"],
    "schwaechen": ["SchwÃ¤che 1", "SchwÃ¤che 2"]
}}"""
    
    response = llm.invoke(prompt)
    return json.loads(response)

# ... analog fÃ¼r die anderen 4 Kriterien
```

### Output
- Bewertungsergebnisse in `metadata.json` unter `bewertung`
- Gesamtscore & Empfehlung

---

## SCHRITT 7: REPORT & CHECKLISTE GENERIEREN

### Ziel
Abschlussreport und Checklisten als Markdown/PDF exportieren.

### UI-Elemente (Streamlit)

```python
# frontend/pages/7_Report.py

import streamlit as st

st.title("ğŸ“„ Report & Checkliste generieren")

projekt_id = st.session_state.get("current_projekt_id")
metadata = load_projekt_metadata(projekt_id)

st.success("âœ… Alle PrÃ¼fungen abgeschlossen!")

# Report-Optionen
st.subheader("ğŸ“‹ Report-Optionen")

report_typ = st.radio(
    "Report-Typ:",
    ["VollstÃ¤ndiger Bewertungsbericht", "FÃ¶rdervoraussetzungen-Checkliste", "Beides"]
)

format_option = st.radio(
    "Format:",
    ["Markdown (.md)", "PDF", "Beides"]
)

# Generieren
if st.button("ğŸ“¥ Report generieren"):
    
    with st.spinner("Report wird erstellt..."):
        
        # Markdown-Reports
        if report_typ in ["VollstÃ¤ndiger Bewertungsbericht", "Beides"]:
            bewertungsbericht = generate_bewertungsbericht_markdown(metadata)
            
            st.download_button(
                label="ğŸ“¥ Bewertungsbericht herunterladen",
                data=bewertungsbericht,
                file_name=f"bewertungsbericht_{projekt_id}.md",
                mime="text/markdown"
            )
        
        if report_typ in ["FÃ¶rdervoraussetzungen-Checkliste", "Beides"]:
            checkliste = generate_checkliste_markdown(metadata['pruefung']['foerdervoraussetzungen'])
            
            st.download_button(
                label="ğŸ“¥ Checkliste herunterladen",
                data=checkliste,
                file_name=f"checkliste_{projekt_id}.md",
                mime="text/markdown"
            )
        
        # Optional: PDF-Generierung
        if "PDF" in format_option:
            st.info("ğŸ’¡ PDF-Generierung noch nicht implementiert. Nutzen Sie Markdown â†’ PDF-Converter.")

# Vorschau
st.subheader("ğŸ‘ï¸ Vorschau: Bewertungsbericht")

with st.expander("Markdown-Vorschau", expanded=True):
    preview = generate_bewertungsbericht_markdown(metadata)
    st.markdown(preview)

# Projekt abschlieÃŸen
st.divider()

if st.button("ğŸ‰ Projekt abschlieÃŸen"):
    metadata["status"] = "completed"
    metadata["completed_at"] = datetime.now().isoformat()
    save_projekt_metadata(projekt_id, metadata)
    
    st.success("âœ… Projekt abgeschlossen!")
    st.balloons()
```

### Backend-Logik

```python
# backend/report_generator.py

def generate_bewertungsbericht_markdown(metadata: dict) -> str:
    """Generiert Bewertungsbericht als Markdown."""
    
    projekt_name = metadata['projekt_name']
    antragsteller = metadata['antragsteller']
    bewertung = metadata['bewertung']
    gesamtscore = metadata['gesamtscore']
    empfehlung = metadata['empfehlung']
    
    md = f"""# Bewertungsbericht

## Projekt: {projekt_name}

**Antragsteller:** {antragsteller}  
**FÃ¶rdermodul:** {metadata['modul']}  
**Erstellt am:** {datetime.now().strftime('%d.%m.%Y %H:%M')}

---

## Executive Summary

**Gesamtbewertung:** {gesamtscore:.1f}/100 Punkte  
**Empfehlung:** {empfehlung}

### Top 3 StÃ¤rken:
"""
    
    # StÃ¤rken sammeln
    alle_staerken = []
    for kriterium, details in bewertung.items():
        alle_staerken.extend(details['staerken'])
    
    for i, staerke in enumerate(alle_staerken[:3], 1):
        md += f"{i}. {staerke}\n"
    
    md += "\n### Top 3 Verbesserungspotenziale:\n"
    
    # SchwÃ¤chen sammeln
    alle_schwaechen = []
    for kriterium, details in bewertung.items():
        alle_schwaechen.extend(details['schwaechen'])
    
    for i, schwaeche in enumerate(alle_schwaechen[:3], 1):
        md += f"{i}. {schwaeche}\n"
    
    # FÃ¶rdervoraussetzungen
    md += "\n---\n\n## FÃ¶rdervoraussetzungen\n\n"
    md += "| Kriterium | Status | BegrÃ¼ndung |\n"
    md += "|-----------|--------|------------|\n"
    
    for key, result in metadata['pruefung']['foerdervoraussetzungen'].items():
        status = "âœ… ErfÃ¼llt" if result['erfuellt'] else "âŒ Nicht erfÃ¼llt"
        md += f"| {result['kriterium']} | {status} | {result['begruendung']} |\n"
    
    # Bewertungskriterien
    md += "\n---\n\n## Bewertung nach Kriterien\n\n"
    
    for key, details in bewertung.items():
        md += f"### {key.replace('_', ' ').title()}\n\n"
        md += f"**Score:** {details['score']}/100\n\n"
        md += f"**BegrÃ¼ndung:** {details['begruendung']}\n\n"
        
        md += "**StÃ¤rken:**\n"
        for staerke in details['staerken']:
            md += f"- {staerke}\n"
        
        md += "\n**SchwÃ¤chen:**\n"
        for schwaeche in details['schwaechen']:
            md += f"- {schwaeche}\n"
        
        md += "\n"
    
    md += "\n---\n\n## Fazit\n\n"
    md += f"Das Projekt '{projekt_name}' erreicht eine Gesamtbewertung von {gesamtscore:.1f}/100 Punkten.\n\n"
    md += f"**Empfehlung:** {empfehlung}\n"
    
    return md

def generate_checkliste_markdown(check_results: dict) -> str:
    """Generiert FÃ¶rdervoraussetzungen-Checkliste als Markdown."""
    
    md = "# FÃ¶rdervoraussetzungen - Checkliste\n\n"
    md += "| # | Kriterium | Status | Wert | BegrÃ¼ndung |\n"
    md += "|---|-----------|--------|------|------------|\n"
    
    for i, (key, result) in enumerate(check_results.items(), 1):
        status = "âœ…" if result['erfuellt'] else "âŒ"
        md += f"| {i} | {result['kriterium']} | {status} | {result['wert']} | {result['begruendung']} |\n"
    
    return md
```

### Output
- Markdown-Reports als Download
- Optional: PDFs
- Projekt-Status auf "completed"

---

## ZUSAMMENFASSUNG

**Wizard-Flow komplett:**
1. âœ… Projekt anlegen â†’ Metadaten erfassen
2. âœ… Dokumente hochladen â†’ Dateien speichern
3. âœ… Parsing â†’ Text/Daten extrahieren
4. âœ… RAG-Indexierung â†’ ChromaDB befÃ¼llen + strukturierte Extraktion
5. âœ… FÃ¶rdervoraussetzungen â†’ 6 Checks + Checkliste
6. âœ… Bewertung â†’ 5 Kriterien + Scoring
7. âœ… Report â†’ Markdown-Export

**Gesamtdauer (geschÃ¤tzt):** 5-10 Minuten pro Projekt

**Ende der Wizard-Flow Dokumentation**
