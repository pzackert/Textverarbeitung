# Dokumentenparsing
## IFB PROFI - Automatisierte Antragspr√ºfung

**Version:** 3.0 (Option 1 MVP + Future Features)  
**Stand:** 13. November 2025

---

## üéØ GRUNDLEGENDES ZIEL

Wir bauen ein optimales RAG-System (Retrieval-Augmented Generation), das Dokumente der IFB Hamburg intelligent verarbeitet. 

### ‚úÖ OPTION 1 (MVP - Super-Lite):
Das System extrahiert den **Volltext** aus allen relevanten Dokumenten. Jedes Dokument wird vollst√§ndig erfasst und f√ºr RAG vorbereitet.

**Fokus Option 1:**
- Nur Text-Extraktion (kein Structure Parsing)
- Einfache Funktionen (keine komplexe OOP-Architektur)
- Drei Formate: PDF, DOCX, XLSX
- Direkter Zugriff mit Libraries

### ‚ö†Ô∏è OPTION 2+ (Advanced Features):
- Strukturerkennung (√úberschriften, Abs√§tze, Listen)
- Tabellen-Extraktion mit Kontext
- Formularfeld-Erkennung
- OCR-Funktionalit√§t
- Parallelverarbeitung
- Caching-System

---

## üìÑ UNTERST√úTZTE DOKUMENTFORMATE

Das System unterst√ºtzt initial die drei wichtigsten Formate:

### PDF-Dokumente (*.pdf) - ‚úÖ OPTION 1

**Verwendung:** Projektskizze, Projektantrag, F√∂rderrichtlinien

**Features Option 1 (MVP):**
- ‚úÖ Vollst√§ndige Textextraktion mit PyMuPDF
- ‚úÖ Einfache Metadaten (Autor, Datum falls vorhanden)

**‚ö†Ô∏è Features Option 2+:**
- Strukturerkennung (√úberschriften, Abs√§tze, Listen)
- Tabellen-Extraktion
- Layout-Analyse

### Word-Dokumente (*.docx) - ‚úÖ OPTION 1

**Verwendung:** Projektskizze, Projektantrag

**Features Option 1 (MVP):**
- ‚úÖ Volltext-Extraktion mit python-docx
- ‚úÖ Basis-Metadaten

**‚ö†Ô∏è Features Option 2+:**
- Formularfeld-Erkennung (Key-Value-Paare)
- Tabellen-Extraktion
- Dokumentenhierarchie (Kapitel, Unterkapitel)

### Excel-Dateien (*.xlsx, *.xls) - ‚úÖ OPTION 1

**Verwendung:** Checklisten, Bewertungstabellen, Projektkalkulation

**Features Option 1 (MVP):**
- ‚úÖ Text aus Zellen extrahieren mit openpyxl
- ‚úÖ Einfache Konvertierung zu Text

**‚ö†Ô∏è Features Option 2+:**
- Intelligente Tabellen-zu-Text-Konvertierung
- Spalten√ºberschriften-Verkn√ºpfung
- Multi-Sheet-Support mit Kontext
- Formeln und Berechnungen

### ‚ö†Ô∏è OCR-Funktionalit√§t - OPTION 2+

**Zuk√ºnftige Erweiterung:**
- Tesseract OCR Integration
- Bildqualit√§ts-Optimierung
- Layout-Analyse f√ºr strukturierte Extraktion

---

## üóÇÔ∏è DOKUMENT-TYPEN

### 1. Projektskizze
**Umfang:** 2-3 Seiten  
**Format:** PDF oder DOCX

**Inhalt:**
- Ansprechpartner (Liste)
- Unternehmensbeschreibung
- Technologischer L√∂sungsansatz
- Marktpotenzial und Vermarktung
- Projektumfang

**Parsing-Strategie:** Volltext-Extraktion mit Abschnittserkennung

### 2. Projektantrag (Formular)
**Umfang:** Mehrseitiges Formular + Anh√§nge  
**Format:** PDF oder DOCX

**Pflichtdokumente:**
- Projektbeschreibung (Formularfelder)
- Projektkalkulation (Excel)
- KMU-Erkl√§rung (PDF)
- Jahresabschl√ºsse (2x PDF)
- Handelsregisterauszug (PDF)
- Finanz- und Arbeitsplatz√ºbersicht (Excel)

**Optional:**
- Lebensl√§ufe (PDF)
- Letters of Intent (PDF)

**Parsing-Strategie:** Formularfelder als Key-Value-Paare + Volltext

---

## üîÑ EXTRAKTIONS-STRATEGIE

### ‚úÖ OPTION 1 (MVP - Super-Lite):

Bei jedem Dokument extrahieren wir **nur den Volltext**:

**Ausgabe Option 1:**
```json
{
  "volltext": "Kompletter Dokumententext...",
  "metadaten": {
    "dokumenttyp": "projektskizze",
    "dateiname": "projektskizze.pdf",
    "dateigr√∂√üe_mb": 2.4
  }
}
```

**Einfache Python-Funktion (Konzept):**
```python
def extract_text_simple(file_path: Path) -> dict:
    """Einfache Textextraktion f√ºr Option 1"""
    suffix = file_path.suffix.lower()
    
    if suffix == '.pdf':
        text = extract_pdf_text(file_path)  # PyMuPDF
    elif suffix == '.docx':
        text = extract_docx_text(file_path)  # python-docx
    elif suffix in ['.xlsx', '.xls']:
        text = extract_excel_text(file_path)  # openpyxl
    else:
        raise ValueError(f"Nicht unterst√ºtztes Format: {suffix}")
    
    return {
        "volltext": text,
        "metadaten": {
            "dokumenttyp": detect_doc_type(file_path.name),
            "dateiname": file_path.name,
            "dateigr√∂√üe_mb": file_path.stat().st_size / (1024*1024)
        }
    }
```

---

### ‚ö†Ô∏è OPTION 2+ (Advanced Extraction):

Zus√§tzlich zur Textextraktion:

**1. Strukturdaten**
√úberschriften, Kapitelnummern, Paragraphen, Listen und Tabellen werden als solche erkannt.

**Ausgabe:**
```json
{
  "struktur": {
    "kapitel": [
      {
        "nummer": "1",
        "titel": "Einleitung",
        "abs√§tze": ["Absatz 1...", "Absatz 2..."]
      }
    ],
    "tabellen": [
      {
        "name": "Kosten√ºbersicht",
        "rows": [...]
      }
    ]
  }
}
```

**2. Erweiterte Metadaten**
```json
{
  "metadaten": {
    "dokumenttyp": "projektskizze",
    "erstellt_am": "2025-03-15",
    "version": "1.2",
    "autor": "Mustermann GmbH",
    "programm": "PROFI Standard",
    "seiten": 3
  }
}
```

---

## üèóÔ∏è MODULARE ARCHITEKTUR

### ‚úÖ OPTION 1 (MVP - Einfache Funktionen):

**Keine OOP-Architektur, nur einfache Funktionen:**

```python
from pathlib import Path
from typing import Dict, Any

def parse_document(file_path: Path) -> Dict[str, Any]:
    """Hauptfunktion f√ºr Dokumentenparsing"""
    suffix = file_path.suffix.lower()
    
    if suffix == '.pdf':
        return parse_pdf_simple(file_path)
    elif suffix == '.docx':
        return parse_docx_simple(file_path)
    elif suffix in ['.xlsx', '.xls']:
        return parse_excel_simple(file_path)
    else:
        raise ValueError(f"Format nicht unterst√ºtzt: {suffix}")

# Keine Factory-Pattern, keine BaseParser-Klasse
# Nur direkte, einfache Funktionen
```

---

### ‚ö†Ô∏è OPTION 2+ (Modulare OOP-Architektur):

Der Code wird strikt modular aufgebaut mit klarer Trennung der Verantwortlichkeiten:

```
DocumentProcessor (Hauptkoordinator)
‚îú‚îÄ‚îÄ FormatDetector (erkennt Dateityp)
‚îú‚îÄ‚îÄ ParserFactory (w√§hlt richtigen Parser)
‚îú‚îÄ‚îÄ Parser-Module
‚îÇ   ‚îú‚îÄ‚îÄ PDFParser
‚îÇ   ‚îú‚îÄ‚îÄ WordParser  
‚îÇ   ‚îú‚îÄ‚îÄ ExcelParser
‚îÇ   ‚îî‚îÄ‚îÄ BaseParser (Fallback)
‚îú‚îÄ‚îÄ TextProcessor (Bereinigung, Normalisierung)
‚îú‚îÄ‚îÄ ChunkGenerator (intelligente Textaufteilung)
‚îî‚îÄ‚îÄ VectorStore (ChromaDB-Integration)
```

**Parser-Schnittstelle:**

Jeder Parser implementiert dieselbe Schnittstelle mit drei Kernmethoden:

```python
class BaseParser(ABC):
    """Basis-Interface f√ºr alle Parser."""
    
    @abstractmethod
    def extract_text(self, file_path: Path) -> str:
        """Holt den Rohtext."""
        pass
    
    @abstractmethod
    def extract_structure(self, file_path: Path) -> dict:
        """Erkennt Dokumentstruktur."""
        pass
    
    @abstractmethod
    def extract_metadata(self, file_path: Path) -> dict:
        """Sammelt Metainformationen."""
        pass
```

**Parser-Factory:**

```python
class ParserFactory:
    """W√§hlt den richtigen Parser basierend auf Dateityp."""
    
    _parsers = {
        ".pdf": PDFParser,
        ".docx": WordParser,
        ".xlsx": ExcelParser,
        ".xls": ExcelParser
    }
    
    @classmethod
    def get_parser(cls, file_path: Path) -> BaseParser:
        """Gibt passenden Parser zur√ºck."""
        suffix = file_path.suffix.lower()
        parser_class = cls._parsers.get(suffix, BaseParser)
        return parser_class()
    
    @classmethod
    def register_parser(cls, extension: str, parser_class: type):
        """Registriert neuen Parser f√ºr Erweiterung."""
        cls._parsers[extension] = parser_class
```

---

## üîß ERWEITERBARKEIT ALS KERNPRINZIP - ‚ö†Ô∏è OPTION 2+

Neue Formate werden durch simple Erg√§nzung unterst√ºtzt:

### Schritte zur Erweiterung:

1. **Neuen Parser erstellen** (z.B. `RTFParser`)
   ```python
   class RTFParser(BaseParser):
       def extract_text(self, file_path: Path) -> str:
           # RTF-spezifische Logik
           pass
   ```

2. **Von BaseParser ableiten**
   - Implementiere alle drei Kernmethoden
   - Verwende bew√§hrte Libraries

3. **In ParserFactory registrieren**
   ```python
   ParserFactory.register_parser(".rtf", RTFParser)
   ```

**Der bestehende Code muss nicht modifiziert werden.** Das System erkennt automatisch das neue Format und nutzt den entsprechenden Parser.

---

## üß© INTELLIGENTES CHUNKING F√úR CHROMADB

### ‚úÖ OPTION 1 (MVP - Einfaches Chunking):

**Simple Text-Splitting:**

```python
def simple_chunk_text(text: str, chunk_size: int = 1000, overlap: int = 200) -> list[str]:
    """
    Einfaches Chunking f√ºr Option 1
    Teilt Text in Chunks mit fester Gr√∂√üe und √úberlappung
    """
    chunks = []
    start = 0
    
    while start < len(text):
        end = start + chunk_size
        chunk = text[start:end]
        chunks.append(chunk)
        start = end - overlap
    
    return chunks
```

**Keine semantischen Grenzen, keine komplexe Logik.**

---

### ‚ö†Ô∏è OPTION 2+ (Intelligentes Chunking):

Dokumente werden intelligent in Chunks aufgeteilt f√ºr optimales RAG-Retrieval:

**Chunking-Strategie:**

#### 1. Semantische Grenzen
Wir trennen an Abs√§tzen und Kapiteln, **nicht mitten im Satz**.

```python
chunk_size = 1000  # Zeichen, keine Token-Limit!
chunk_overlap = 200  # 20% √úberlappung
separators = ["\n\n", "\n", ". ", " ", ""]
```

#### 2. Kontexterhaltung
Chunks √ºberlappen sich um 20%, damit Zusammenh√§nge nicht verloren gehen.

**Beispiel:**
```
Chunk 1: "...Ende von Absatz 1. Beginn Absatz 2..."
Chunk 2: "Beginn Absatz 2... Ende Absatz 2. Beginn Absatz 3..."
```

#### 3. Flexible Gr√∂√üe
- Kurze Abschnitte bleiben zusammen
- Lange werden sinnvoll geteilt
- Tabellen bleiben vollst√§ndig zusammen

#### 4. Metadaten-Vererbung
Jeder Chunk wei√ü, aus welchem Dokument, Kapitel und Abschnitt er stammt.

```json
{
  "chunk_id": "chunk_001",
  "text": "Chunk-Inhalt...",
  "metadata": {
    "dokument_id": "projektskizze_001",
    "dokumenttyp": "projektskizze",
    "kapitel": "1. Einleitung",
    "seite": 1,
    "chunk_index": 0
  }
}
```

---

## üéØ SPEZIALBEHANDLUNG F√úR IFB-DOKUMENTE - ‚ö†Ô∏è OPTION 2+

**In Option 1: Nur einfache Textextraktion, keine Spezialbehandlung.**

**Option 2+ Features:**

### Projektskizzen
**Formularfelder** werden als Key-Value-Paare extrahiert. Die Feldbezeichnung wird mit dem Inhalt verkn√ºpft f√ºr pr√§zise Suche.

**Beispiel:**
```json
{
  "formularfelder": {
    "Projektname": "Entwicklung einer KI-gest√ºtzten Verpackungsanlage",
    "Antragsteller": "Mustermann GmbH",
    "Projektlaufzeit": "24 Monate",
    "Gesamtkosten": "450.000 EUR"
  }
}
```

### Projektantr√§ge
**Mehrseitige Antr√§ge** behalten ihre Abschnittsstruktur. Anh√§nge werden erkannt und verlinkt.

**Beispiel:**
```json
{
  "abschnitte": [
    {
      "nummer": "A",
      "titel": "Projektbeschreibung",
      "inhalt": "..."
    },
    {
      "nummer": "B",
      "titel": "Projektkalkulation",
      "anhang": "kalkulation.xlsx"
    }
  ]
}
```

### Checklisten
**Kriterien und Bewertungen** werden strukturiert erfasst. Checkboxen werden in maschinenlesbare Ja/Nein-Werte √ºbersetzt.

**Beispiel:**
```json
{
  "kriterien": [
    {
      "id": "K001",
      "beschreibung": "Betriebsst√§tte in Hamburg",
      "status": true,
      "bewertung": "erf√ºllt"
    }
  ]
}
```

---

## ‚úÖ QUALIT√ÑTSSICHERUNG

### ‚úÖ OPTION 1 (Basis-Qualit√§tssicherung):

**UTF-8 √ºberall:**
Deutsche Umlaute und Sonderzeichen werden korrekt behandelt.

```python
with open(file_path, "r", encoding="utf-8") as f:
    content = f.read()
```

**Einfache Fehlerbehandlung:**
```python
try:
    text = parse_document(file_path)
except Exception as e:
    print(f"Fehler beim Parsen: {e}")
    text = ""
```

---

### ‚ö†Ô∏è OPTION 2+ (Erweiterte Qualit√§tssicherung):

**Fehlertoleranz:**
Besch√§digte Dokumente f√ºhren nicht zum Absturz. Der Parser extrahiert, was m√∂glich ist, und loggt Probleme.

```python
try:
    text = parser.extract_text(file_path)
except ParsingError as e:
    logger.warning(f"Parsing-Fehler in {file_path}: {e}")
    text = parser.extract_partial_text(file_path)
```

**Vollst√§ndigkeitspr√ºfung:**
Nach dem Parsing wird verifiziert, dass kein Inhalt verloren ging.

```python
def verify_completeness(original_file: Path, extracted_text: str) -> bool:
    """Pr√ºft, ob Extraktion vollst√§ndig ist."""
    original_size = original_file.stat().st_size
    extracted_size = len(extracted_text.encode('utf-8'))
    
    # Warnung bei gro√üer Diskrepanz
    if extracted_size < original_size * 0.5:
        logger.warning(f"Nur {extracted_size}/{original_size} Bytes extrahiert")
        return False
    
    return True
```

---

## üõ†Ô∏è TECHNISCHE UMSETZUNG

### ‚úÖ OPTION 1 - Verwendete Libraries:

**PyMuPDF (fitz)** f√ºr PDF-Verarbeitung
- Schnell und zuverl√§ssig
- Vollst√§ndige Textextraktion
```bash
pip install PyMuPDF
```

**python-docx** f√ºr Word-Dokumente
- Native DOCX-Unterst√ºtzung
```bash
pip install python-docx
```

**openpyxl** f√ºr Excel-Files
- Vollst√§ndige Format-Unterst√ºtzung
```bash
pip install openpyxl
```

**ChromaDB** als lokale Vektor-Datenbank
- Embedding-Speicherung
- Similarity-Search
```bash
pip install chromadb
```

**sentence-transformers** f√ºr Embeddings
- Multilingual support
```bash
pip install sentence-transformers
```

**Streamlit** f√ºr UI
```bash
pip install streamlit
```

---

### ‚ö†Ô∏è OPTION 2+ - Zus√§tzliche Libraries:

**langchain** als Orchestrierung f√ºr das RAG-System
- Text-Splitting
- Embedding-Integration
- Vector-Store-Anbindung
```bash
pip install langchain
```

---

### Code-Dokumentation - ‚úÖ OPTION 1

Der Code wird mit **Docstrings** dokumentiert. Jede Funktion erkl√§rt ihre Parameter und R√ºckgabewerte.

**Beispiel:**
```python
def parse_document(file_path: Path) -> dict:
    """
    Parst ein Dokument und extrahiert Text.
    
    Args:
        file_path: Pfad zur Datei (PDF, DOCX oder XLSX)
    
    Returns:
        dict mit volltext und metadaten
    
    Example:
        >>> result = parse_document(Path("projektskizze.pdf"))
        >>> print(result["volltext"][:100])
    """
    pass
```

---

## ‚ö° PERFORMANCE-OPTIMIERUNG - ‚ö†Ô∏è OPTION 2+

**In Option 1: Keine Parallelverarbeitung, kein Caching, keine Batch-Operationen.**

**Option 2+ Features:**

### Parallelverarbeitung
Mehrere Dokumente werden gleichzeitig geparst (multiprocessing).

```python
from multiprocessing import Pool

def parse_documents_parallel(file_paths: list[Path]) -> list[ParseResult]:
    """Parst mehrere Dokumente parallel."""
    with Pool(processes=4) as pool:
        results = pool.map(parse_document, file_paths)
    return results
```

### Caching
Bereits verarbeitete Dokumente werden markiert und nicht erneut geparst.

```python
def is_cached(file_path: Path) -> bool:
    """Pr√ºft, ob Dokument bereits geparst wurde."""
    cache_file = get_cache_path(file_path)
    return cache_file.exists()

def load_from_cache(file_path: Path) -> ParseResult:
    """L√§dt geparstes Ergebnis aus Cache."""
    cache_file = get_cache_path(file_path)
    with open(cache_file, "r", encoding="utf-8") as f:
        return ParseResult.from_json(f.read())
```

### Batch-Operationen
Embeddings werden in Gruppen generiert f√ºr bessere Effizienz.

```python
def generate_embeddings_batch(chunks: list[str], batch_size: int = 100):
    """Generiert Embeddings in Batches."""
    for i in range(0, len(chunks), batch_size):
        batch = chunks[i:i+batch_size]
        embeddings = embedding_model.embed(batch)
        yield embeddings
```

---

## üìä ERWARTETES ERGEBNIS

### ‚úÖ OPTION 1 (MVP):

Nach dem Parsing haben wir:

‚úÖ **Vollst√§ndigen, durchsuchbaren Text** aller Dokumente  
‚úÖ **Basis-Metadaten** (Dateiname, Typ)
‚úÖ **Einfache Chunks** f√ºr RAG-Retrieval  

**Beispiel-Output Option 1:**

```json
{
  "volltext": "Kompletter Text der Projektskizze...",
  "metadaten": {
    "dateiname": "projektskizze.pdf",
    "dokumenttyp": "projektskizze",
    "dateigr√∂√üe_mb": 2.4
  },
  "chunks": [
    "Chunk 1 Inhalt...",
    "Chunk 2 Inhalt...",
    "Chunk 3 Inhalt..."
  ]
}
```

---

### ‚ö†Ô∏è OPTION 2+ (Erweitert):

‚úÖ **Strukturierte Metadaten** f√ºr pr√§zise Filterung  
‚úÖ **Intelligente Chunks** mit Kontext
‚úÖ **Erweiterbare Codebasis** f√ºr zuk√ºnftige Anforderungen  

**Beispiel-Output Option 2+:**

```json
{
  "dokument_id": "projektskizze_001",
  "dokumenttyp": "projektskizze",
  "volltext": "Kompletter Text der Projektskizze...",
  "struktur": {
    "kapitel": [...],
    "tabellen": [...]
  },
  "metadaten": {
    "dateiname": "projektskizze.pdf",
    "erstellt_am": "2025-03-15",
    "seiten": 3
  },
  "chunks": [
    {
      "chunk_id": "chunk_001",
      "text": "Chunk 1 Inhalt...",
      "metadata": {...}
    }
  ],
  "vector_ids": ["vec_001", "vec_002", ...]
}
```

---

## üéì ANWENDUNGSBEISPIEL - ‚úÖ OPTION 1 + ‚ö†Ô∏è OPTION 2+

**Funktioniert in beiden Optionen:**

Das System erm√∂glicht es, Fragen wie:

**"Welche Voraussetzungen hat das PROFI-Programm?"**  
‚Üí RAG findet relevante Textstellen aus F√∂rderrichtlinien

**"Was steht in der Projektskizze zum Thema Innovation?"**  
‚Üí RAG extrahiert Abschnitt "Technologischer L√∂sungsansatz"

**"Ist das Unternehmen KMU-berechtigt?"**  
‚Üí RAG findet Informationen aus KMU-Erkl√§rung und Jahresabschl√ºssen

pr√§zise zu beantworten, indem es die relevanten Textstellen aus den geparsten Dokumenten findet und dem LLM zur Verf√ºgung stellt.

---

## üîê SICHERHEIT - ‚ö†Ô∏è OPTION 2+

**In Option 1: Nur lokale Verarbeitung, keine erweiterten Sicherheitsfeatures.**

**Option 2+ Features:**

### Datei-Validierung
- Dateityp-Pr√ºfung vor Verarbeitung
- Gr√∂√üenlimits (max. 50 MB pro Datei)
- Virus-Scan (optional integrierbar)

### Sandbox-Ausf√ºhrung
- Parser laufen in isolierter Umgebung
- Kein Zugriff auf Systemressourcen
- Timeout bei h√§ngenden Operationen

### Datenschutz
- Lokale Verarbeitung (keine Cloud)
- Verschl√ºsselte Speicherung m√∂glich
- DSGVO-konform

---

*Diese Spezifikation dient als Arbeitsgrundlage f√ºr die Implementierung des Dokumentenparsing-Moduls. Jeder Abschnitt kann in konkrete Entwicklungs-Tasks √ºbersetzt werden.*