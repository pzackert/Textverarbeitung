[run]
repetitions = 3
warmup = true

[hyperparameters]
temperature = [0.0, 0.7]
# Expanded context length sweep for large-document RAG benchmarks.
context_length = [2048, 4096, 8192, 16384, 32768, 65536]

[[models]]
name = "qwen2.5:0.5b"
backend = "ollama"
enabled = true

[[models]]
name = "qwen2.5:7b"
backend = "ollama"
enabled = true

[[models]]
# Use available smaller Mistral variant to avoid missing model errors
name = "ministral-3:3b"
backend = "ollama"
enabled = true

